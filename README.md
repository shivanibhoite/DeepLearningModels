# DeepLearningModels

This project aims to build a trainable deep learning model that helps in the classification of the text, based upon the toxicity score of the emotions conveyed through
the text. This project will help classify and train the neural network for identification of the toxicity scores of any given text.

Everyone has a phone these days, and with the phone, EVERYONE has access to one of the social
media platforms. (97 percent of the teens are online and the vast majority of them have access to
internet) These platforms provide an environment where people can freely engage in discussions
and express their opinions with regards to the events happening around them. These events can
be anything ranging from news articles, politics to the weather. The people actively engage in
this discussion, and sometimes the comments refer to each other. This leads to active one on one
discussions arise.
When views of people do not match, it leads to offensive and abusive talks via such comments,
beginning to severe cases of cyberbullying.

Passing on toxic text which leads to cyberbullying cases. It is a real problem in society today. (34
percent of people feel they have been cyberbullied in their lifetime). To monitor that the cases of
cyberbullying do not occur, the owner companies of chat forums had to deploy a human interference
for monitoring. However, as human moderation is expensive and time- consuming, mostly the
companies have deployed an automated machine learning model for the classification of the toxic
text.
The goal of this project is to identify the toxicity level of the text and eliminate the human intervention as little as possible
